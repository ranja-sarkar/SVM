{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import PyPDF2\n",
    "\n",
    "filepath1 = \"GS.06.52850_Volume_swelling_of_FFKM_FKM_and_HNBR_elastomers_in_Saraline_Paraffins.pdf\"\n",
    "pdfFileObj = open(filepath1, 'rb') \n",
    "pdfreader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "count1 = pdfreader.numPages\n",
    "\n",
    "text1 = []\n",
    "for j in range(count1):\n",
    "    page = pdfreader.getPage(j)\n",
    "    pp = page.extractText()\n",
    "    text1.append(pp)\n",
    "\n",
    "#print(text1)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open('C:/Users/Ranja.Sarkar/Chemical compatibility Elastomers and Metals.pdf')\n",
    "#doc1 = str(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "     return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "     return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF-IDF is for search query relevance\n",
    "\n",
    "text1 = 'There is no change in hardness under ambient temperatures.'\n",
    "text2 = 'There is change in hardness upon exposure to the solvent.'\n",
    "text3 = 'There is change in hardness upon high pressure.'\n",
    "test_set = [text1, text2, text3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'there': 12, 'is': 6, 'no': 7, 'change': 1, 'in': 5, 'hardness': 3, 'under': 14, 'ambient': 0, 'temperature': 10, 'upon': 15, 'exposure': 2, 'to': 13, 'the': 11, 'solvent': 9, 'high': 4, 'pressure': 8}\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LemVectorizer = CountVectorizer(tokenizer = LemNormalize, stop_words = 'english')\n",
    "LemVectorizer = CountVectorizer(tokenizer = LemNormalize)\n",
    "LemVectorizer.fit_transform(test_set)\n",
    "\n",
    "print(LemVectorizer.vocabulary_), print(len(LemVectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0]\n",
      " [0 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1]\n",
      " [0 1 0 1 1 1 1 0 1 0 0 0 1 0 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix = LemVectorizer.transform(test_set).toarray()\n",
    "print(tf_matrix)\n",
    "\n",
    "tf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf = tf x idf\n",
    "#idf(t) = log((n+1)/(df(d,t)+1)) + 1 ##n = total number of documents, df = number of documents in which term t appears ##prevents zero divisions\n",
    "\n",
    "#generally speaking, certain terms do occur more than others\n",
    "#tf-idf scales up the importance of rarer terms and scales down the importance of more frequent terms relative to the whole corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import math\n",
    "#def idf(n,df):\n",
    "#    result = math.log((n+1.0)/(df+1.0)) + 1\n",
    "#    return result\n",
    "#print(\"The idf for terms that appear in one document: \" + str(idf(4,1)))\n",
    "#print()\"The idf for terms that appear in two documents: \" + str(idf(4,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.69314718 1.         1.69314718 1.         1.69314718 1.\n",
      " 1.         1.69314718 1.69314718 1.69314718 1.69314718 1.69314718\n",
      " 1.         1.69314718 1.69314718 1.28768207]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidfTran = TfidfTransformer(norm = \"l2\")\n",
    "tfidf = tfidfTran.fit(tf_matrix)\n",
    "#print(tfidf)\n",
    "print(tfidfTran.idf_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41724161 0.24642961 0.         0.24642961 0.         0.24642961\n",
      "  0.24642961 0.41724161 0.         0.         0.41724161 0.\n",
      "  0.24642961 0.         0.41724161 0.        ]\n",
      " [0.         0.23488735 0.39769885 0.23488735 0.         0.23488735\n",
      "  0.23488735 0.         0.         0.39769885 0.         0.39769885\n",
      "  0.23488735 0.39769885 0.         0.30246022]\n",
      " [0.         0.28407693 0.         0.28407693 0.48098405 0.28407693\n",
      "  0.28407693 0.         0.48098405 0.         0.         0.\n",
      "  0.28407693 0.         0.         0.36580076]]\n"
     ]
    }
   ],
   "source": [
    "#cosine similarity matrix is obtained by multiplying the if-idf matrix by its transpose\n",
    "tfidf_matrix = tfidfTran.transform(tf_matrix)\n",
    "print(tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.28941599 0.35002483]\n",
      " [0.28941599 1.         0.44427055]\n",
      " [0.35002483 0.44427055 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "cos_similarity_matrix = (tfidf_matrix * tfidf_matrix.T).toarray()\n",
    "print(cos_similarity_matrix)\n",
    "\n",
    "#Similarity matrix says that text2 and text3 are more similar to each other than other pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination of CountVectorizer & TfidfTransformer (TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#StopWords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.28941599 0.35002483]\n",
      " [0.28941599 1.         0.44427055]\n",
      " [0.35002483 0.44427055 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#TfidfVec = TfidfVectorizer(tokenizer = LemNormalize, stop_words = 'english')\n",
    "TfidfVec = TfidfVectorizer(tokenizer = LemNormalize)\n",
    "\n",
    "def cos_similarity(textlist):\n",
    "    tfidf = TfidfVec.fit_transform(textlist)\n",
    "    return (tfidf * tfidf.T).toarray()\n",
    "\n",
    "print(cos_similarity(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "filepath = \"GS.08.54388_Failure_analysis_of_aramid_reinforced_guide-straps_ex_Brigantine_platform.pdf\"\n",
    "pdfFileObj = open(filepath, 'rb') \n",
    "pdfreader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "count = pdfreader.numPages\n",
    "\n",
    "text = ''\n",
    "for j in range(count):\n",
    "    page = pdfreader.getPage(j)\n",
    "    pp = page.extractText()\n",
    "    text = text + pp\n",
    "\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_summarizer(raw_docx):\n",
    "    docx = nlp(raw_docx)\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    \n",
    "    # Build Word Frequency; word.text is tokenization in spacy\n",
    "    word_frequencies = {}  \n",
    "    for word in docx:  \n",
    "        if word.text not in stopwords:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1\n",
    "\n",
    "    # weighted frequency of each word (over most occurring word); long sentences over short sentences \n",
    "    maximum_frequency = max(word_frequencies.values())\n",
    "\n",
    "    for word in word_frequencies.keys():  \n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequency)\n",
    "    # Sentence Tokens\n",
    "    sentence_list = [sentence for sentence in docx.sents]\n",
    "\n",
    "    # sentence score; ranking of words in each sentence\n",
    "    sentence_scores = {}  \n",
    "    for sent in sentence_list:  \n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if len(sent.text.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "\n",
    "    # Find N Largest: finding top N sentences with largest scores\n",
    "    summary_sentences = nlargest(5, sentence_scores, key = sentence_scores.get)\n",
    "    final_sentences = [w.text for w in summary_sentences ]\n",
    "    summary = ' '.join(final_sentences)\n",
    "#    print(\"Original Document\\n\")\n",
    "#    print(raw_docx)\n",
    "#    print(\"Total Length:\", len(raw_docx))\n",
    "#    print('\\nSummarized Document\\n')\n",
    "    print(summary)\n",
    "#    print(\"Total Length:\", len(summary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________ \n",
      "7.1 CTS 01 - ROV GVI of Riser 2 \n",
      "Report Criticality Date Component Anomalies Video \n",
      " Page 22 8 Drawings___________________________________________ \n",
      " Page 11 5 Video Logs_________________________________________ \n",
      " _________________________________________ \n",
      " Page 1 1 Introduction________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_summarizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
